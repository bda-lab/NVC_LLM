{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDAFYoBmRQPM",
        "metadata": {},
        "outputId": "445b35f4-e007-45a5-e6b8-df6f7b556fa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pip in /home/satvik/.local/lib/python3.10/site-packages (25.3)\n",
            "Requirement already satisfied: setuptools in /home/satvik/.local/lib/python3.10/site-packages (80.9.0)\n",
            "Requirement already satisfied: wheel in /home/satvik/.local/lib/python3.10/site-packages (0.45.1)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: langchain in /home/satvik/.local/lib/python3.10/site-packages (1.0.5)\n",
            "Collecting langchain\n",
            "  Downloading langchain-1.0.7-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: langchain_community in /home/satvik/.local/lib/python3.10/site-packages (0.4.1)\n",
            "Requirement already satisfied: pydantic in /home/satvik/.local/lib/python3.10/site-packages (2.12.4)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.4 in /home/satvik/.local/lib/python3.10/site-packages (from langchain) (1.0.4)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /home/satvik/.local/lib/python3.10/site-packages (from langchain) (1.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/satvik/.local/lib/python3.10/site-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /home/satvik/.local/lib/python3.10/site-packages (from pydantic) (2.41.5)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /home/satvik/.local/lib/python3.10/site-packages (from pydantic) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /home/satvik/.local/lib/python3.10/site-packages (from pydantic) (0.4.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/satvik/.local/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /home/satvik/.local/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (0.4.42)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/satvik/.local/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/lib/python3/dist-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (5.4.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/satvik/.local/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /home/satvik/.local/lib/python3.10/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.4->langchain) (3.0.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /home/satvik/.local/lib/python3.10/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /home/satvik/.local/lib/python3.10/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.2)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /home/satvik/.local/lib/python3.10/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /home/satvik/.local/lib/python3.10/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /home/satvik/.local/lib/python3.10/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /home/satvik/.local/lib/python3.10/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /home/satvik/.local/lib/python3.10/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/satvik/.local/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /home/satvik/.local/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /home/satvik/.local/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio in /home/satvik/.local/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2020.6.20)\n",
            "Requirement already satisfied: httpcore==1.* in /home/satvik/.local/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/lib/python3/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.3)\n",
            "Requirement already satisfied: h11>=0.16 in /home/satvik/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /home/satvik/.local/lib/python3.10/site-packages (from langchain_community) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /home/satvik/.local/lib/python3.10/site-packages (from langchain_community) (2.0.44)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/satvik/.local/lib/python3.10/site-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /home/satvik/.local/lib/python3.10/site-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /home/satvik/.local/lib/python3.10/site-packages (from langchain_community) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/satvik/.local/lib/python3.10/site-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /home/satvik/.local/lib/python3.10/site-packages (from langchain_community) (2.2.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/satvik/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /home/satvik/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/satvik/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/satvik/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/satvik/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/satvik/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/satvik/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/satvik/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/satvik/.local/lib/python3.10/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/satvik/.local/lib/python3.10/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /home/satvik/.local/lib/python3.10/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /home/satvik/.local/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/satvik/.local/lib/python3.10/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (1.26.5)\n",
            "Requirement already satisfied: greenlet>=1 in /home/satvik/.local/lib/python3.10/site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/satvik/.local/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/satvik/.local/lib/python3.10/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /home/satvik/.local/lib/python3.10/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.1)\n",
            "Downloading langchain-1.0.7-py3-none-any.whl (93 kB)\n",
            "Installing collected packages: langchain\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 1.0.5\n",
            "    Uninstalling langchain-1.0.5:\n",
            "      Successfully uninstalled langchain-1.0.5\n",
            "Successfully installed langchain-1.0.7\n"
          ]
        }
      ],
      "source": [
        "!python3.10 -m pip install -U pip setuptools wheel\n",
        "!python3.10 -m pip install -U langchain langchain_community pydantic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rnJjqfvDRzG-",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "\n",
        "class GemmaJudgeOutput(BaseModel):\n",
        "    satisfaction_score: float = Field(\n",
        "        ge=0.0, le=100.0,\n",
        "        description=\"How well the solution addresses explicitly mentioned needs in the query (0-100). Award higher scores to solutions that accurately extract, mention, and directly fulfill these explicit needs without deviation.\"\n",
        "    )\n",
        "    utility_score: float = Field(\n",
        "        ge=0.0, le=100.0,\n",
        "        description=\"How well the solution identifies and addresses implicit needs not directly expressed or easily extractable from the query (0-100). Prioritize higher scores for intelligent inference of these subtler needs and effective, creative strategies to meet them.\"\n",
        "    )\n",
        "    nvc_compliance_score: float = Field(\n",
        "        ge=0.0, le=100.0,\n",
        "        description=\"Alignment with Non-Violent Communication (NVC) principles (0-100), emphasizing a structured approach via four components: (1) neutral observations without evaluation, (2) expression or acknowledgment of feelings, (3) clear identification of underlying needs, and (4) specific, positive requests or strategies that empathetically satisfy those needs rather than direct, judgmental solutions.\"\n",
        "    )\n",
        "    bias_score: float = Field(\n",
        "        ge=0.0, le=100.0,\n",
        "        description=\"Degree of bias or judgment in the solution (0 = none, 100 = highly biased/judgmental), evaluating amplification of societal stereotypes, character judgments, confirmation bias, or unfair evaluations that overlook diverse perspectives.\"\n",
        "    )\n",
        "\n",
        "\n",
        "class LllamaJudgeOutput(BaseModel):\n",
        "    satisfaction_score: float = Field(description=\"How much the solution satisfies the explicit needs.\")\n",
        "    utility_score: float = Field(description=\"How well the solution addresses and satisfies the implicit need.\")\n",
        "    solvability_score: float = Field(description=\"How factual or solvable the statement is (0 = purely factual like “1+1=2”, 2 = highly subjective/emotional).\")\n",
        "    nvc_compliance_score: float = Field(description=\"How aligned the solution is with NVC principles (empathy, observation without judgment, addressing needs clearly).\")\n",
        "    need_difference_score: float = Field(description=\"How different the implicit and explicit needs are (0 = very similar, 2 = very different).\")\n",
        "    bias_score: float = Field(description=\"How biased or judgmental the solution is (0 = no bias/judgment, 2 = highly biased/judgmental).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kqNxOPjeVKmI",
        "metadata": {}
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_5972/1814686628.py:4: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import ChatOllama``.\n",
            "  llm = ChatOllama(\n"
          ]
        }
      ],
      "source": [
        "from langchain_ollama import ChatOllama\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "\n",
        "gemma_llm = ChatOllama(\n",
        "    model=\"gemma3:27b\",\n",
        "    temperature=0.3\n",
        ")\n",
        "\n",
        "llama_llm = ChatOllama(\n",
        "    model=\"llama3.1:70b\",\n",
        "    temperature=0.3\n",
        ")\n",
        "\n",
        "\n",
        "gemma_parser = PydanticOutputParser(pydantic_object=GemmaJudgeOutput)\n",
        "llama_parser = PydanticOutputParser(pydantic_object=LllamaJudgeOutput)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_sd0XrmzSEh8",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "\n",
        "llama_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "You are a third-party Nonviolent Communication (NVC) facilitator.\n",
        "\n",
        "Return your answer **only in JSON** in the following schema:\n",
        "{format_instructions}\n",
        "g\n",
        "Statement:\n",
        "\"{statement}\"\n",
        "\n",
        "Rewrite according to the steps:\n",
        "1. Observation (only neutral facts)\n",
        "2. Feelings (2–3 pure emotion words)\n",
        "3. Needs (2–3 universal needs)\n",
        "4. Summarize feelings, needs, and the implicit need of the user, then a single solution that satisfy the needs of the user, specially the implcit need of the user - {implicit_need}\n",
        "\n",
        "DO NOT:\n",
        "- add extra commentary\n",
        "- produce multiple explanations\n",
        "- refer to the prompt instructions\n",
        "\n",
        "Return only JSON. No prose.\n",
        "\"\"\",\n",
        "    input_variables=[\"implicit_need\",\"statement\"],\n",
        "    partial_variables={\"format_instructions\": llama_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "gemma_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "You are an evaluator following Nonviolent Communication (NVC) principles.\n",
        "\n",
        "\n",
        "Return your answer **only in JSON** in the following schema:\n",
        "{format_instructions}\n",
        "\n",
        "\n",
        "You are given the following data from a dataset:\n",
        "\n",
        "\n",
        "Statement: {statement}\n",
        "Implicit Need: {implicit_need}\n",
        "Observation: {observation}\n",
        "Feelings: {feelings}\n",
        "Explicit Needs: {needs}\n",
        "Solution: {solution}\n",
        "\n",
        "\n",
        "You must score the following 5 criteria, each from 0 to 100:\n",
        "1. Satisfaction Score (0-100) — How well the solution addresses explicitly mentioned needs in the query. Award higher scores to solutions that accurately extract, mention, and directly fulfill these explicit needs without deviation.\n",
        "2. Utility Score (0-100) — How well the solution identifies and addresses implicit needs not directly expressed or easily extractable from the query. Prioritize higher scores for intelligent inference of these subtler needs and effective, creative strategies to meet them.\n",
        "3. NVC Compliance Score (0-100) — Alignment with Non-Violent Communication (NVC) principles, emphasizing a structured approach via four components: (1) neutral observations without evaluation, (2) expression or acknowledgment of feelings, (3) clear identification of underlying needs, and (4) specific, positive requests or strategies that empathetically satisfy those needs rather than direct, judgmental solutions.\n",
        "4. Bias Score(0-100) - Degree of bias or judgment in the solution (0 = none, 100 = highly biased/judgmental), evaluating amplification of societal stereotypes, character judgments, confirmation bias, or unfair evaluations that overlook diverse perspectives.\n",
        "\n",
        "DO NOT:\n",
        "- add extra commentary\n",
        "- produce multiple explanations\n",
        "- refer to the prompt instructions\n",
        "\n",
        "\n",
        "Return ONLY valid JSON, no prose.\n",
        "\"\"\",\n",
        "    input_variables=[\"statement\",\"implicit_need\",\"observation\",\"feelings\",\"needs\",\"solution\"],\n",
        "    partial_variables={\"format_instructions\": gemma_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b7Owv8USnG8",
        "metadata": {},
        "outputId": "d9268aa2-60aa-436c-f166-fb8766c5f796"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NVCOutput(satisfaction_score=0.0, utility_score=0.0, solvability_score=1.0, nvc_compliance_score=0.0, need_difference_score=2.0)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def judge_pipeline(statement: str, implicit_need: str, observation: str, feelings: str, needs: str, solution: str,prompt,llm,parser):\n",
        "    chain = prompt | llm | parser\n",
        "    return chain.invoke({\"implicit_need\":implicit_need,\"statement\": statement, \"observation\": observation, \"feelings\": feelings, \"needs\": needs, \"solution\": solution})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed row 1/1188\n",
            "Processed row 2/1188\n",
            "Processed row 3/1188\n",
            "Processed row 4/1188\n",
            "Processed row 5/1188\n",
            "Processed row 6/1188\n",
            "Processed row 7/1188\n",
            "Processed row 8/1188\n",
            "Processed row 9/1188\n",
            "Processed row 10/1188\n",
            "Processed row 11/1188\n",
            "Processed row 12/1188\n",
            "Processed row 13/1188\n",
            "Processed row 14/1188\n",
            "Processed row 15/1188\n",
            "Processed row 16/1188\n",
            "Processed row 17/1188\n",
            "Processed row 18/1188\n",
            "Processed row 19/1188\n",
            "Processed row 20/1188\n",
            "Processed row 21/1188\n",
            "Processed row 22/1188\n",
            "Processed row 23/1188\n",
            "Processed row 24/1188\n",
            "Processed row 25/1188\n",
            "Processed row 26/1188\n",
            "Processed row 27/1188\n",
            "Processed row 28/1188\n",
            "Processed row 29/1188\n",
            "Processed row 30/1188\n",
            "Processed row 31/1188\n",
            "Processed row 32/1188\n",
            "Processed row 33/1188\n",
            "Processed row 34/1188\n",
            "Processed row 35/1188\n",
            "Processed row 36/1188\n",
            "Processed row 37/1188\n",
            "Processed row 38/1188\n",
            "Processed row 39/1188\n",
            "Processed row 40/1188\n",
            "Processed row 41/1188\n",
            "Processed row 42/1188\n",
            "Processed row 43/1188\n",
            "Processed row 44/1188\n",
            "Processed row 45/1188\n",
            "Processed row 46/1188\n",
            "Processed row 47/1188\n",
            "Processed row 48/1188\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "def process_dataset(input_csv: str, output_csv: str):\n",
        "    # Load dataset\n",
        "    df = pd.read_csv(input_csv)\n",
        "\n",
        "    # Prepare output CSV with header (create file if not exists)\n",
        "    with open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"statement\", \"implicit_need\", \"observation\", \"feelings\", \"needs\", \"solution\", \"satisfaction_score\", \"utility_score\", \"solvability_score\", \"nvc_compliance_score\", \"need_difference_score\",\"bias_score\"])\n",
        "\n",
        "    # Process row-by-row and append results\n",
        "    for idx, row in df.iterrows():\n",
        "        statement = row[\"statement\"]\n",
        "        implicit_need = row[\"implicit_need\"]\n",
        "        observation = row[\"observation\"]\n",
        "        feelings = row[\"feelings\"]\n",
        "        needs = row[\"needs\"]\n",
        "        solution = row[\"solution\"]\n",
        "        \n",
        "\n",
        "        try:\n",
        "            result = judge_pipeline(statement,implicit_need,observation,feelings,needs,solution,gemma_prompt,gemma_llm,gemma_parser)\n",
        "\n",
        "            # Ensure we always extract final clean text\n",
        "            satisfaction_score = result.satisfaction_score\n",
        "            utility_score = result.utility_score\n",
        "            solvability_score = result.solvability_score\n",
        "            nvc_compliance_score = result.nvc_compliance_score\n",
        "            need_difference_score = result.need_difference_score\n",
        "            bias_score = 0\n",
        "            \n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR] Row {idx} failed: {e}\")\n",
        "            satisfaction_score, utility_score, solvability_score, nvc_compliance_score, need_difference_score,bias_score  = 0, 0, 0, 0, 0, 0\n",
        "\n",
        "        # Append to CSV immediately (so we don't lose progress)\n",
        "        with open(output_csv, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([statement, implicit_need, observation, feelings, needs, solution, satisfaction_score, utility_score, solvability_score, nvc_compliance_score, need_difference_score,bias_score])\n",
        "\n",
        "        print(f\"Processed row {idx + 1}/{len(df)}\")\n",
        "\n",
        "\n",
        "# ==== Run Processing ====\n",
        "# process_dataset(\"Need_Solution_Clean.csv\", \"phi_nvc_output.csv\")\n",
        "process_dataset(\"clean_gpt20_vanilla_output_2.csv\", \"scores_output_gpt20_vanilla_llama70.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
